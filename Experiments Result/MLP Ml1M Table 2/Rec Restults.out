python code/recommenders_training.py 
tensor([[   0,    0,    0,  ..., 4828, 4828, 4828],
        [  31,  179,  236,  ..., 3026, 3190, 3305]])
torch.Size([2, 461252])
tensor([[4829, 4829, 4829,  ..., 9417, 9417, 9417],
        [6065, 6069, 6078,  ..., 5882, 5914, 6031]])
torch.Size([2, 113876])
tensor([[4829, 4829, 4829,  ..., 9417, 9417, 9417],
        [6047, 6068, 6085,  ..., 5846, 5877, 5930]])
torch.Size([2, 113876])
======================== new run - MLP ========================
train pos_loss = 0.25666207467254837, neg_loss = 0.24109944936476255
this model is saved as MLP_ML1M_0_256.pt
test pos_loss = 0.26969924569129944, neg_loss = 0.21075491607189178
hit_at_10 is 89, hit_at_50 is 207, hit_at_100 is 269
0.07367549668874172 0.17135761589403972 0.222682119205298 0.012417218543046357 33.51481104967185
train pos_loss = 0.2430644364733445, neg_loss = 0.22698898456598582
this model is saved as MLP_ML1M_1_256.pt
test pos_loss = 0.2202460616827011, neg_loss = 0.23902714252471924
hit_at_10 is 85, hit_at_50 is 210, hit_at_100 is 321
0.07036423841059603 0.173841059602649 0.26572847682119205 0.014072847682119206 28.32658545710251
train pos_loss = 0.23101370507165006, neg_loss = 0.2239755015624197
this model is saved as MLP_ML1M_2_256.pt
test pos_loss = 0.26783958077430725, neg_loss = 0.19328323006629944
hit_at_10 is 93, hit_at_50 is 218, hit_at_100 is 312
0.07698675496688742 0.1804635761589404 0.2582781456953642 0.012417218543046357 26.521136816373506
train pos_loss = 0.23628477124791397, neg_loss = 0.20235999242255562
this model is saved as MLP_ML1M_3_256.pt
test pos_loss = 0.2573592960834503, neg_loss = 0.1852221041917801
hit_at_10 is 96, hit_at_50 is 241, hit_at_100 is 337
0.07947019867549669 0.19950331125827814 0.27897350993377484 0.01903973509933775 22.286599638415748
train pos_loss = 0.21963717827671453, neg_loss = 0.21200793275707647
this model is saved as MLP_ML1M_4_256.pt
test pos_loss = 0.2465212196111679, neg_loss = 0.2163810282945633
hit_at_10 is 82, hit_at_50 is 206, hit_at_100 is 325
0.06788079470198675 0.17052980132450332 0.26903973509933776 0.009933774834437087 24.7309663859785
train pos_loss = 0.22925218312363876, neg_loss = 0.1973246422253157
this model is saved as MLP_ML1M_5_256.pt
test pos_loss = 0.30021172761917114, neg_loss = 0.1721663475036621
        hit_at_10 is 90, hit_at_50 is 243, hit_at_100 is 335
0.07450331125827815 0.201158940397351 0.277317880794702 0.008278145695364239 22.679940101580502
train pos_loss = 0.2149338275194168, neg_loss = 0.20613461027019903
this model is saved as MLP_ML1M_6_256.pt
test pos_loss = 0.2633308172225952, neg_loss = 0.19405023753643036
hit_at_10 is 86, hit_at_50 is 254, hit_at_100 is 352
0.07119205298013245 0.21026490066225165 0.2913907284768212 0.014900662251655629 22.472533499434892
train pos_loss = 0.2088659758630552, neg_loss = 0.2062888176817643
this model is saved as MLP_ML1M_7_256.pt
test pos_loss = 0.34557798504829407, neg_loss = 0.14623932540416718
hit_at_10 is 81, hit_at_50 is 221, hit_at_100 is 334
0.06705298013245033 0.18294701986754966 0.2764900662251656 0.015728476821192054 23.598003843057498
train pos_loss = 0.22111066705302188, neg_loss = 0.19590575757779574
this model is saved as MLP_ML1M_8_256.pt
test pos_loss = 0.257617324590683, neg_loss = 0.20849855244159698
hit_at_10 is 73, hit_at_50 is 218, hit_at_100 is 314
0.060430463576158944 0.1804635761589404 0.2599337748344371 0.0173841059602649 23.10312694038168
======================== new run - MLP ========================
train pos_loss = 0.3658220648765564, neg_loss = 0.19668986201286315
this model is saved as MLP_ML1M_0_512.pt
test pos_loss = 0.34667474031448364, neg_loss = 0.20473560690879822
hit_at_10 is 35, hit_at_50 is 96, hit_at_100 is 145
0.028973509933774833 0.07947019867549669 0.12003311258278146 0.0033112582781456954 37.226583694232104
train pos_loss = 0.3846587657928467, neg_loss = 0.16186431497335435
this model is saved as MLP_ML1M_1_512.pt
test pos_loss = 0.26738402247428894, neg_loss = 0.2417757660150528
hit_at_10 is 34, hit_at_50 is 95, hit_at_100 is 138
0.028145695364238412 0.07864238410596026 0.11423841059602649 0.005794701986754967 40.22848269742681
train pos_loss = 0.31238701939582825, neg_loss = 0.19380588233470916
this model is saved as MLP_ML1M_2_512.pt
test pos_loss = 0.3681774139404297, neg_loss = 0.15551325678825378
hit_at_10 is 88, hit_at_50 is 180, hit_at_100 is 244
0.0728476821192053 0.1490066225165563 0.20198675496688742 0.016556291390728478 31.133540372670765
train pos_loss = 0.2854746639728546, neg_loss = 0.19300825297832488
this model is saved as MLP_ML1M_3_512.pt
test pos_loss = 0.31153202056884766, neg_loss = 0.16536112129688263
hit_at_10 is 89, hit_at_50 is 194, hit_at_100 is 289
0.07367549668874172 0.1605960264900662 0.2392384105960265 0.014900662251655629 27.23223467331071
train pos_loss = 0.31393293142318723, neg_loss = 0.1528355747461319
this model is saved as MLP_ML1M_4_512.pt
test pos_loss = 0.28406569361686707, neg_loss = 0.1780896931886673
hit_at_10 is 83, hit_at_50 is 210, hit_at_100 is 312
0.06870860927152318 0.173841059602649 0.2582781456953642 0.011589403973509934 26.124123706493844
train pos_loss = 0.27131499648094176, neg_loss = 0.1705340176820755
this model is saved as MLP_ML1M_5_512.pt
test pos_loss = 0.3229791224002838, neg_loss = 0.1492440402507782
hit_at_10 is 91, hit_at_50 is 221, hit_at_100 is 324
0.07533112582781457 0.18294701986754966 0.2682119205298013 0.014072847682119206 24.776898954226166
train pos_loss = 0.2763050436973572, neg_loss = 0.16008559763431549
this model is saved as MLP_ML1M_6_512.pt
test pos_loss = 0.2899361252784729, neg_loss = 0.16234751045703888
hit_at_10 is 84, hit_at_50 is 226, hit_at_100 is 329
0.0695364238410596 0.1870860927152318 0.2723509933774834 0.015728476821192054 23.63925990782144
train pos_loss = 0.2629100799560547, neg_loss = 0.149450945854187
this model is saved as MLP_ML1M_7_512.pt
test pos_loss = 0.2957354784011841, neg_loss = 0.15501655638217926
hit_at_10 is 100, hit_at_50 is 249, hit_at_100 is 359
0.08278145695364239 0.20612582781456953 0.29718543046357615 0.018211920529801324 21.239748418803174
train pos_loss = 0.259614959359169, neg_loss = 0.14695702791213988
this model is saved as MLP_ML1M_8_512.pt
test pos_loss = 0.31573423743247986, neg_loss = 0.1406848430633545
hit_at_10 is 109, hit_at_50 is 263, hit_at_100 is 352
0.0902317880794702 0.21771523178807947 0.2913907284768212 0.02152317880794702 20.708610250895624
train pos_loss = 0.2574327319860458, neg_loss = 0.13923884630203248
this model is saved as MLP_ML1M_9_512.pt
test pos_loss = 0.30628731846809387, neg_loss = 0.13772115111351013
hit_at_10 is 98, hit_at_50 is 260, hit_at_100 is 362
0.08112582781456953 0.2152317880794702 0.2996688741721854 0.01903973509933775 20.53793011589895
train pos_loss = 0.24727120697498323, neg_loss = 0.14926253259181976
this model is saved as MLP_ML1M_10_512.pt
test pos_loss = 0.29665639996528625, neg_loss = 0.1421409398317337
hit_at_10 is 89, hit_at_50 is 250, hit_at_100 is 360
0.07367549668874172 0.20695364238410596 0.2980132450331126 0.014900662251655629 20.7069208334068
train pos_loss = 0.26118583381175997, neg_loss = 0.13360161185264588
this model is saved as MLP_ML1M_11_512.pt
test pos_loss = 0.2864120304584503, neg_loss = 0.14592894911766052
hit_at_10 is 95, hit_at_50 is 243, hit_at_100 is 357
0.07864238410596026 0.201158940397351 0.2955298013245033 0.014072847682119206 20.15509342233872
train pos_loss = 0.23568007349967957, neg_loss = 0.1447485387325287
this model is saved as MLP_ML1M_12_512.pt
test pos_loss = 0.32952070236206055, neg_loss = 0.11879628896713257
hit_at_10 is 103, hit_at_50 is 261, hit_at_100 is 364
0.08526490066225166 0.21605960264900662 0.30132450331125826 0.018211920529801324 19.531453525838764
train pos_loss = 0.23213994801044463, neg_loss = 0.13974785208702087
this model is saved as MLP_ML1M_13_512.pt
test pos_loss = 0.2959039807319641, neg_loss = 0.137991800904274
hit_at_10 is 109, hit_at_50 is 259, hit_at_100 is 372
0.0902317880794702 0.2144039735099338 0.3079470198675497 0.013245033112582781 19.202653707610356
train pos_loss = 0.2630490094423294, neg_loss = 0.12482983767986297
this model is saved as MLP_ML1M_14_512.pt
test pos_loss = 0.2932485044002533, neg_loss = 0.13519969582557678
hit_at_10 is 107, hit_at_50 is 282, hit_at_100 is 392
0.08857615894039735 0.23344370860927152 0.32450331125827814 0.013245033112582781 18.160185179744236
train pos_loss = 0.2232888877391815, neg_loss = 0.1410745918750763
this model is saved as MLP_ML1M_15_512.pt
test pos_loss = 0.34350889921188354, neg_loss = 0.10652029514312744
hit_at_10 is 109, hit_at_50 is 296, hit_at_100 is 398
0.0902317880794702 0.24503311258278146 0.3294701986754967 0.014072847682119206 18.44158337103916
train pos_loss = 0.24724208414554597, neg_loss = 0.11966058760881423
this model is saved as MLP_ML1M_16_512.pt
test pos_loss = 0.3083132803440094, neg_loss = 0.1302272379398346
hit_at_10 is 94, hit_at_50 is 271, hit_at_100 is 397
0.07781456953642384 0.22433774834437087 0.32864238410596025 0.01076158940397351 18.867071735114994
train pos_loss = 0.2423764705657959, neg_loss = 0.12553972750902176
this model is saved as MLP_ML1M_17_512.pt
test pos_loss = 0.34019529819488525, neg_loss = 0.11432589590549469
hit_at_10 is 105, hit_at_50 is 264, hit_at_100 is 394
0.0869205298013245 0.2185430463576159 0.326158940397351 0.012417218543046357 18.1766631213384
train pos_loss = 0.22301144003868104, neg_loss = 0.13129442036151887
this model is saved as MLP_ML1M_18_512.pt
test pos_loss = 0.3168417811393738, neg_loss = 0.12702429294586182
hit_at_10 is 104, hit_at_50 is 270, hit_at_100 is 378
0.08609271523178808 0.22350993377483444 0.3129139072847682 0.015728476821192054 18.28079489786126
train pos_loss = 0.2306399554014206, neg_loss = 0.12652739137411118
this model is saved as MLP_ML1M_19_512.pt
test pos_loss = 0.34385091066360474, neg_loss = 0.11609749495983124
hit_at_10 is 103, hit_at_50 is 256, hit_at_100 is 364
0.08526490066225166 0.2119205298013245 0.30132450331125826 0.013245033112582781 18.84447271566271
======================== new run - MLP ========================
train pos_loss = 0.3212595378097735, neg_loss = 0.21526131700528295
this model is saved as MLP_ML1M_0_512.pt
test pos_loss = 0.3510415256023407, neg_loss = 0.17644870281219482